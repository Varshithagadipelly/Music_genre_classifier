{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import json\n",
        "import librosa\n",
        "\n",
        "# Define all possible genres\n",
        "all_genres = [\n",
        "    \"country\", \"blues\", \"hiphop\", \"disco\", \"pop\",\n",
        "    \"rock\", \"jazz\", \"classical\", \"metal\", \"reggae\"\n",
        "]\n",
        "\n",
        "# Set your constants\n",
        "SAMPLE_RATE = 22050\n",
        "TRACK_DURATION = 30  # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "\n",
        "\n",
        "# Define the function to extract MFCCs from a single audio file\n",
        "def extract_mfcc(file_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
        "    data = {\n",
        "        \"mfcc\": []\n",
        "    }\n",
        "\n",
        "    samples_per_track = SAMPLE_RATE * TRACK_DURATION\n",
        "    samples_per_segment = int(samples_per_track / num_segments)\n",
        "    expected_num_frames = 216  # Number of frames per segment\n",
        "\n",
        "    # Load audio file\n",
        "    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "    # Extract MFCC for each segment\n",
        "    for segment in range(num_segments):\n",
        "        start_sample = samples_per_segment * segment\n",
        "        finish_sample = start_sample + samples_per_segment\n",
        "\n",
        "        mfcc = librosa.feature.mfcc(y=signal[start_sample:finish_sample],\n",
        "                                     sr=sample_rate,\n",
        "                                     n_fft=n_fft,\n",
        "                                     n_mfcc=num_mfcc,\n",
        "                                     hop_length=hop_length)\n",
        "        mfcc = mfcc.T  # Transpose to match shape (time steps, coefficients)\n",
        "\n",
        "        # Ensure the shape of MFCC data for this segment matches the expected shape\n",
        "        if mfcc.shape[0] == expected_num_frames:\n",
        "            data[\"mfcc\"].append(mfcc.tolist())\n",
        "        else:\n",
        "            # If the number of frames does not match, pad or truncate the MFCC data\n",
        "            if mfcc.shape[0] < expected_num_frames:\n",
        "                # Padding\n",
        "                mfcc = np.pad(mfcc, ((0, expected_num_frames - mfcc.shape[0]), (0, 0)), 'constant')\n",
        "            else:\n",
        "                # Truncation\n",
        "                mfcc = mfcc[:expected_num_frames, :]\n",
        "            data[\"mfcc\"].append(mfcc.tolist())\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "def predict(model, X):\n",
        "    \"\"\"\n",
        "    Predicts the class label for the input data using the trained model.\n",
        "\n",
        "    Args:\n",
        "    - model: The trained classifier model\n",
        "    - X: Input data\n",
        "\n",
        "    Returns:\n",
        "    - predicted_label: The predicted class label\n",
        "    \"\"\"\n",
        "    # Perform prediction\n",
        "    predictions = model.predict(X)\n",
        "    # print('hi')\n",
        "    print(predictions)\n",
        "    # Get the index of the class with the highest probability\n",
        "    predicted_index = np.argmax(predictions, axis=1)\n",
        "    # print('hey')\n",
        "    return predicted_index\n",
        "\n",
        "\n",
        "model = keras.models.load_model('/content/drive/MyDrive/saved_models/music_cnn.h5')\n",
        "\n",
        "\n",
        "# Define your prediction function\n",
        "def predict_genre(audio_file_path):\n",
        "    # Assuming you have functions extract_mfcc, predict, and necessary variables defined elsewhere\n",
        "    # Extract MFCCs from the audio file\n",
        "    extracted_features = extract_mfcc(audio_file_path)\n",
        "    # Extract the MFCC data\n",
        "    mfcc_data = np.array(extracted_features[\"mfcc\"])\n",
        "    # Add an axis to input data for sample\n",
        "    mfcc_data = mfcc_data[..., np.newaxis]  # Shape: (num_segments, 216, 13, 1)\n",
        "\n",
        "    # Load the mapping\n",
        "    with open('mapping.json', 'r') as f:\n",
        "      mapping = json.load(f)\n",
        "\n",
        "    # Predict the genre\n",
        "    predicted_labels = predict(model, mfcc_data)\n",
        "\n",
        "    # Map predicted indices to genre labels\n",
        "    predicted_labels = [mapping[str(idx)] for idx in predicted_labels]\n",
        "    print(\"Predicted Genres:\", predicted_labels)\n",
        "    # Count the occurrences of each predicted label\n",
        "    label_counts = Counter(predicted_labels)\n",
        "\n",
        "    # Get the label with the maximum count\n",
        "    max_label = max(label_counts, key=label_counts.get)\n",
        "    print(\"Predicted Genre:\", max_label)\n",
        "    # Calculate percentages for each genre\n",
        "    total_samples = len(predicted_labels)\n",
        "    genre_percentages = {genre: label_counts.get(genre, 0) / total_samples * 100 for genre in all_genres}\n",
        "\n",
        "    return max_label, genre_percentages\n",
        "\n",
        "# Define Gradio Interface\n",
        "def audio_interface(audio_file):\n",
        "    predicted_genre, genre_distribution = predict_genre(audio_file)\n",
        "\n",
        "    # Create a bar graph showing genre distribution\n",
        "    genres = list(genre_distribution.keys())\n",
        "    percentages = list(genre_distribution.values())\n",
        "    plt.bar(genres, percentages)\n",
        "    plt.xlabel('Genre')\n",
        "    plt.ylabel('Percentage')\n",
        "    plt.title('Genre Distribution')\n",
        "    plt.ylim(0, 100)  # Set y-axis limits from 0 to 100\n",
        "    plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n",
        "    plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
        "    plt.savefig(\"genre_distribution.png\")  # Save the plot as an image\n",
        "    plt.close()  # Close the plot to prevent displaying it\n",
        "\n",
        "    return predicted_genre, \"genre_distribution.png\"  # Return the predicted genre and the path to the generated graph\n",
        "\n",
        "gr.Interface(fn=audio_interface,\n",
        "             inputs=\"file\",\n",
        "             outputs=[\"text\", \"image\"],\n",
        "             title=\"Music Genre Prediction\",\n",
        "             description=\"Upload an audio file and get the predicted genre along with genre distribution percentages.\").launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "id": "ErrEzcNilHDq",
        "outputId": "a8df1ab2-93fe-45ed-924d-52c0d3544a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://d93a6b231d2881e21d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d93a6b231d2881e21d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 283ms/step\n",
            "[[1.22742523e-02 1.00198486e-04 2.68474780e-03 2.14876421e-03\n",
            "  1.28539994e-01 9.18735823e-05 3.34574375e-04 1.96656331e-01\n",
            "  1.19034623e-04 6.57050133e-01]\n",
            " [7.92527385e-03 1.33878540e-03 5.38019638e-04 2.34496524e-03\n",
            "  9.60428119e-01 7.55790415e-06 2.33366110e-04 2.34597200e-03\n",
            "  3.48298545e-06 2.48345099e-02]\n",
            " [1.42089775e-05 2.43861649e-07 5.84799318e-06 6.19136990e-05\n",
            "  9.99903440e-01 6.11725426e-09 2.20360448e-07 3.01950718e-06\n",
            "  6.06830364e-10 1.10869842e-05]\n",
            " [5.26570191e-04 5.97840190e-05 4.98507172e-04 6.37956802e-03\n",
            "  9.90385056e-01 9.53031304e-06 1.52739340e-05 2.94530455e-05\n",
            "  8.82562517e-07 2.09538662e-03]\n",
            " [2.70266555e-05 3.05119116e-04 1.00080587e-03 2.58874439e-04\n",
            "  9.98382211e-01 1.42699787e-06 8.34124165e-08 2.72702960e-06\n",
            "  5.61209497e-08 2.16002190e-05]]\n",
            "Predicted Genres: ['reggae', 'pop', 'pop', 'pop', 'pop']\n",
            "Predicted Genre: pop\n"
          ]
        }
      ]
    }
  ]
}
